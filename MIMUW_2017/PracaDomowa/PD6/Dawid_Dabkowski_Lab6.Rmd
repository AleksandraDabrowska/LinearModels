---
title: "cw6"
author: "Dawid D¹bkowski"
date: "21.03.2017"
output: html_document
---

```{r, warning=F, message=F}
library(rmarkdown)
library(dplyr)
library(ggplot2)
library(lattice)
library(e1071)
library(lmtest)
library(partykit)
```
Plan na spotkanie

Pobierz plik `df.rda` i wykonaj na nim poniÅ¼sze zadania https://github.com/pbiecek/LinearModels/blob/master/MIMUW_2017/Lab/df.rda

```{r}
load("df.rda")
summary(df)
```

1. Wykonaj analizÄ™ jednokierunkowÄ… wariancji ze zmiennÄ… `V1`. Ustaw poziom `B` jako poziom referencyjny.

```{r}
df$V1 <- relevel(df$V1, ref="B")
model1 <- lm(y~V1, data=df)
(a1 <- anova(model1))
summary(model1)
```

Zmienna zaleÅ¼y od V1, wszystkie poziomy V1 odbiegajÄ… od referencyjnej Å›redniej B.

2. PoÅ‚Ä…cz w zmiennych `V1` i `V2` poziomy `B` i `C` ze sobÄ…, a nastÄ™pnie wykonaj test weryfikujÄ…cy istotnoÅ›Ä‡ interakcji.

```{r}
df <- mutate(df, V1 = ifelse(V1 %in% c("B","C"), "BC", "A"))
df$V1 <- as.factor(df$V1)
df <- mutate(df, V2 = ifelse(V2 %in% c("B","C"), "BC", "A"))
df$V2 <- as.factor(df$V2)

interaction.plot(df$V1, df$V2, df$y)
model2 <- lm(y~V1*V2, data=df)
summary(model2)
(a2 <- anova(model2))
```

Interakcje nie zachodz¹.

3. Dla zmiennej `V1` porÃ³wnaj wyniki dla rÃ³Å¼nych kontrastÃ³w, przynajmniej Helmerta, poly i sum.

```{r}
model3 <- lm(y~V1, data=df, contrasts=list(V1=contr.helmert(2)))
summary(model3)
model4 <- lm(y~V1, data=df, contrasts=list(V1=contr.poly(2)))
summary(model4)
model5 <- lm(y~V1, data=df, contrasts=list(V1=contr.sum(2)))
summary(model5)
```

Wszystkie kontrasty pokazujÄ… istotnoÅ›Ä‡ kolejnych grup referencyjnych.

4. Wykonaj test post hoc dla zmiennej `V3`. KtÃ³re poziomy rÃ³Å¼niÄ… siÄ™ pomiÄ™dzy sobÄ…?

```{r}
(t6 <- TukeyHSD(aov(y~V3, data=df)))
plot(t6, las=1)
```

Å»adne poziomy nie rÃ³Å¼niÄ… siÄ™ istotnie Å›rednimi.

5. Zweryfikuj istotnoÅ›Ä‡ zaleÅ¼noÅ›ci od zmiennej `V4`

```{r}
model7 <- lm(y~V4, data=df)
summary(model7)
```

Odrzucamy hipotezÄ™ o zaleÅ¼noÅ›ci od zmiennej V4.

6. Czy istotna jest interakcja pomiÄ™dzy V4 a V1? Jak pokazaÄ‡ tÄ™ zaleÅ¼noÅ›Ä‡.

```{r}
model8 <- lm(y~V4*V1, data=df)
summary(model8)
(a8 <- anova(model8))
xyplot(y~V4|V1, data=df, type=c("p","r"))
```

Interakcja nie jest istotna (pomimo tego, Å¼e wykres sugeruje co innego).

7. Zweryfikuj zaleÅ¼noÅ›Ä‡ od zmiennej `V5`. A co jeÅ¼eli ta zaleÅ¼noÅ›Ä‡ nie jest liniowa? SprawdÅº zaleÅ¼noÅ›Ä‡ od wielomianu stopnia 3.

```{r}
model9 <- lm(y~V5, data=df)
summary(model9)
(a9 <- anova(model9))
```

ZaleÅ¼noÅ›Ä‡ liniowa nie jest istotna. Sprawdzimy zaleÅ¼noÅ›Ä‡ od wielomianu stopnia 3.

```{r}
plot(df$V5, df$y)
model10 <- lm(y~poly(V5,3), data=df)
summary(model10)
(a10 <- anova(model10))
```

Widzimy zaleÅ¼noÅ›Ä‡ od wielomianu stopnia 3 (a wÅ‚aÅ›ciwie to lepszÄ… od wielomianu stopnia 2).

8. Zbuduj nowÄ… zmiennÄ… `NV := V4 - 2*V5`. Zbadaj zwiÄ…zek z tÄ… zmiennÄ….

```{r}
df <- mutate(df, NV=V4-2*V5)
model11 <- lm(y~NV, data=df)
summary(model11)
(a11 <- anova(model11))
```

ZaleÅ¼noÅ›Ä‡ nie jest istotna.

9. Wybierz model optymalny wedÅ‚ug kryterium BIC - zrÃ³b przeglÄ…d peÅ‚ny wszystkich modeli.

```{r}
zm <- colnames(df)[2:12]
wsp = (bincombinations(length(zm))==1)[-1,]
params = matrix(0, nrow(wsp), 4)
for (i in 1:nrow(wsp)) {
     form = as.formula(paste("y~", paste(zm[wsp[i,]], collapse="+")))
     model12 = lm(form, data=df)
     params[i,1] = AIC(model12, k=log(nrow(df)))
     params[i,2] = model12$rank
     params[i,3] = summary(model12)$adj.r.squared
     params[i,4] = AIC(model12)
}
params <- as.data.frame(params)
colnames(params) <- c("BIC", "rank", "adjR2", "AIC")
head(params)
```

Model optymalny wed³ug kryterium BIC:

```{r}
as.formula(paste("y~",paste(zm[wsp[which.min(params$BIC),]], collapse="+")))
```

10. Wybierz model optymalny wedÅ‚ug kryterium AIC - uÅ¼yj funkcji step.

```{r}
tmpFun = function(fit, aic) {
     list(size = length(fit$coefficients), aic = aic, likelihood = logLik(fit)) 
}

 model13 = step(lm(y~., data=df), k=2, keep=tmpFun, trace=0)

 kolumny = colnames(df)[2:12]
 maxModel = as.formula(paste("~",paste(kolumny,collapse="+")))

# od modelu pustego do optymalnego
model14 = step(lm(y~1, data=df), scope=list(upper = maxModel, lower = ~1), direction ="forward", k=2, keep=tmpFun, trace=0)

# od wybranego modelu do optymalnego
model15 = step(lm(y~V1+V4, data=df), scope=list(upper = maxModel, lower = ~1), k=2, keep=tmpFun, trace=0)
 
model15$keep
```

Narysujmy œcie¿ki.

```{r}
getMD <- function(md) {
  data.frame(size = unlist(apply(md, 2, `[`, 1)),
             aic = unlist(apply(md, 2, `[`, 2)))
}

df1 <- getMD(model13$keep)
df2 <- getMD(model14$keep)
df4 <- getMD(model15$keep)

pl <- ggplot() +
  geom_point(data=df1, aes(size, aic)) +
  geom_line(data=df1, aes(size, aic)) +
  geom_point(data=df2, aes(size, aic), color="blue") +
  geom_line(data=df2, aes(size, aic), color="blue") +
  geom_point(data=df4, aes(size, aic), color="red")  +
  geom_line(data=df4, aes(size, aic), color="red") 

pl
pl + xlim(15,25) + ylim(-4780, -4750)
```

Jak widaæ metod¹ step otrzymujemy tu ten sam model, bez wzglêdu na to czy startujemy z modelu pustego, pe³nego czy wybranego. Jest to model:

```{r}
model13
model14
model15
```

11. Wykonaj diagnostykÄ™ reszt. Czy sÄ… obserwacje odstajÄ…ce/wpÅ‚ywowe?

```{r}
plot(model15, which=1:6)
bptest(model15)
```

Residuals vs Fitted: Reszty nie zale¿¹ wyraŸnie od zmiennej objaœnianej. Wynik pozytywny.

Normal Q-Q: Kwantyle uk³adaj¹ siê z grubsza wzd³u¿ przek¹tnej. Pewien problem z lewym ogonem. Wynik neutralny.

Scale Location: Wariancja reszt nie zale¿y istotnie od zmiennej objaœnianej. Wynik pozytywny.

Residuals vs Leverage: Nie widzimy obserwacji o bardzo odstaj¹cej dŸwigni. Wynik pozytywny.

Cook's distance: Wszystkie obserwacje s¹ typowe, miara Cook'a poni¿ej 1. Wynik pozytywny.

Cook's dist vs Leverage: Raczej nie ma obserwacji bardzo wp³ywowych. Wynik pozytywny.

bptest: Wariancje reszt nie s¹ jednorodne. Wynik negatywny.

12. Zweryfikuj istotnoÅ›Ä‡ interakcji `V6` i `V7`.

```{r}
model16 <- lm(y~V6:V7, data=df)
summary(model16)
(a16 <- anova(model16))
```

Interakcje te nie s¹ istotne.

13. PorÃ³wnaj wyniki z wynikami funkcji `ctree` pakiet `partykit`.

```{r}
(r17 <- ctree(y~., data=df))
```

14. UÅ¼yj funkcji `optim()` aby znaleÅºÄ‡ oceny wspÃ³Å‚czynnikÃ³w z kryterium do optymalizacji `abs(y - Xb)`
15. Funkcja `rlm` z pakietu `MASS` wykonuje regresjÄ™ odpornÄ…. SprawdÅº jak wpÅ‚ynie ona na ocenÄ™ wspÃ³Å‚czynnikÃ³w.