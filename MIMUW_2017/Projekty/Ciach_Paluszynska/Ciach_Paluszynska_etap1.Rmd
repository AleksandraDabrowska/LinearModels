---
title: "Czynniki wp³ywaj¹ce na czas rozwi¹zywania zadañ z matematyki PISA 2015 - etap 1"
author: "Micha³ Ciach, Ola Paluszyñska"
date: "16 kwietnia 2017"
output: 
    html_document:
        toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(ggplot2)
library(moments) # obliczanie kurtozy i skoœnoœci rozk³adów
library(MASS)
library(nortest) # testy na normalnoœæ rozk³adu (Shapiro-Wilk nie dzia³a dla wektorów d³u¿szych ni¿ 5000)
library(car) # funkcja qqPlot rysuje QQ-plot z przedzia³ami ufnoœci
library(lmtest)
library(gridExtra)
library(stringr)
setwd("~/UW/Modele_Liniowe_i_Mieszane/Projekt")
```

# Dane

Analizowane przez nas dane dotycz¹ czasu rozwi¹zywania zadañ z matematyki PISA 2015. Struktura zbioru danych jest nastêpuj¹ca:

```{r}
load("actionTimeScoreMath.rda")
task_data <- actionTimeScoreMath; rm(actionTimeScoreMath)
names(task_data)[names(task_data) == "T"] <- "time"
str(task_data)
head(task_data)
```

Zmienne oznaczaj¹ kolejno: kraj (`CNT`), id szko³y (`CNTSCHID`), id studenta (`CNTSTUID`), id kwestionariusza (`BOOKID`), kod zadania (`item_short`), przedmiot (`subject`, CM to matematyka, CR to czytanie, a DR to nauki przyrodnicze), liczbê klikniêæ w trakcie rozwi¹zywania zadania (`A`), punkty za zadanie (`S`), czas rozwi¹zywania zadania (`time`) oraz pozycja zadania w kwestionariuszu (`position`).

Kod zadania zawiera dwie sk³adowe: id zadania oraz numer podpunktu (Q01, Q02, Q03, Q04 oraz Q05). Na potrzeby analizy rozdzielimy te dwie sk³adowe tworz¹c dwie nowe zmienne (`task` to id zadania i `Q` to numer podpunktu) ¿eby umo¿liwiæ analizowanie ich oddzielnie:

```{r}
task_data$task <- gsub("Q\\d+", "", task_data$item_short)
task_data$task <- as.factor(task_data$task)
table(task_data$task)
task_data$Q <- gsub("M\\d+\\D?Q", "Q", task_data$item_short)
task_data$Q <- as.factor(task_data$Q)
table(task_data$Q)
```

Liczba zadañ w zbiorze danych wynosi `r length(levels(task_data$task))`. Macierz kontyngencji zadanie/podpunkt:

```{r}
table(task_data$task, task_data$Q)
```

Jak widaæ, nie wszystkie zadania maj¹ wszystkie podpunkty. W szczególnoœci niektóre zadania nie maj¹ podpunktu piewrszego. Dlatego wprowadzimy dodatkow¹ numeracjê podpunktów, która odzwierciedla ich kolejnoœæ (np. jeœli w zadaniu nie by³o podpunktu Q01 to w nowej zmiennej bêdzie zamiast podpunktu Q02 w starej wersji). Pozwsta³¹ w ten sposób zmienn¹ nazwiemy `Q.nb`.

```{r}
non.empty <- apply(table(task_data$task, task_data$Q), 1, function(x) ifelse(x == 0, 0, 1))
question.id <- apply(non.empty, 2, function(x) ifelse(x==0, 0, cumsum(x)))
task_data$Q.nb <- apply(task_data, 1, function(x) question.id[x["Q"], x["task"]])
task_data$Q.nb <- as.factor(task_data$Q.nb)
# head(task_data[task_data$task=="M00K", ])
```

Poniewa¿ nasz¹ zmienn¹ objaœnian¹ jest czas rozwi¹zywania zadania, usuniemy ze zbioru danych wszystkie obserwacje, dla których brakuje wartoœci tej zmiennej (gdybyœmy tego nie zrobili, to musielibyœmy to robiæ np. przy liczeniu wszelkich statystyk w dalszej czêœci analizy).

```{r}
task_data <- task_data[!is.na(task_data$time),]
```

Nastêpnie przytniemy wartoœci zmiennej `time` przekraczaj¹ce 500000 (zmienna ta jest w milisekundach, czyli patrzymy na wartoœci przekraczaj¹ce 8 i 1/3 minuty), gdy¿ takie czasy pojawiaj¹ siê prawdopodobnie ze wzglêdu na problemy przy zbieraniu danych (np. uczeñ wyszed³ do toalety lub nie wy³¹czy³ komputera).

```{r}
task_data[task_data$time > 500000, "time"] <- 500000
```

W celu przyspieszenia obliczeñ bêdziemy pracowaæ tylko na czêœci naszego zbioru danych, do której wybraliœmy co czwart¹ szko³ê z ka¿dego kraju (kod wybieraj¹cy te szko³y znajduje siê w czêœci 2 pracy):

```{r}
chosen_schools <- read.csv("Chosen_schools.csv")
sample_data <- task_data[task_data$CNTSCHID %in% chosen_schools$x, ]
rm(chosen_schools)
save(sample_data, file = "sample_data.rda")
```

# Model liniowy zbudowany na cechach zadania

## Analizowane zmienne

### Kodowanie zmiennych objaœniaj¹cych

Zanim zbudujemy model liniowy powinniœmy zastanowiæ siê, w jaki sposób w³¹czyæ do niego nasze trzy jakoœciowe zmienne objaœniaj¹ce: zadanie (`task`), podpunkt (`Q`) oraz pozycja w kwestionariuszu (`position`). Domyœlnie bêdziemy u¿ywaæ kodowania referencyjnego, a wiêc dla ka¿dej ze zmiennych musimy wybraæ kategoriê bazow¹. Poniewa¿ kategoria ta powinna byæ mo¿liwie liczna (w przeciwnym razie oszacowania parametrów mog¹ byæ nieistotne ze wzglêdu na to, ¿e stanowi¹ one o ró¿nicy wzglêdem kategorii bazowej), w przypadku zadania wybierzemy kategoriê wystêpuj¹c¹ najczêœciej, czyli `r names(which.max(table(sample_data$task)))`, natomiast w przypadku podpunktu oraz pozycji w kwestionariuszu wybierzemy podpunkt i pozycjê pierwsz¹, które wydaj¹ siê byæ naturalnymi punktami odniesienia (przy okazji s¹ to kategorie najliczniejsze).

```{r}
# Zmieniamy kategoriê, która jest pierwsza czyli bêdzie brana jako bazowa
task_data <- within(task_data, position <- relevel(position, ref = 2))
task_data <- within(task_data, task <- relevel(task, ref = 43))
sample_data <- within(sample_data, position <- relevel(position, ref = 2))
sample_data <- within(sample_data, task <- relevel(task, ref = 43))
```

### Rozk³ad zmiennej objaœnianej

Jednym z za³o¿eñ modelu liniowego jest normalnoœæ rozk³adu reszt. Problem ze spe³nieniem tego za³o¿enia zwykle rozwi¹zuje siê stosuj¹c pewn¹ transformacjê zmiennej objaœnianej przed docelowym modelowaniem, co rozwa¿ymy w tej czêœci analizy.

### Rozk³ad w ca³ym zbiorze a rozk³ad w podpróbce

W naszym przypadku zmienna objaœniana (nawet po zastosowanym przyciêciu wartoœci do 5 minut) ma bardzo d³ugi i cienki prawy ogon, co mo¿e przenieœæ siê na podobny problem reszt modelu. Poni¿ej przedstawiamy wybrane percentyle, równie¿ dla ca³ego zbioru dla porównania:

```{r}
rbind(Full = quantile(task_data$time, probs = c(0.25, 0.5, 0.75, 0.9, 0.98, 1)),
Sample = quantile(sample_data$time, probs = c(0.25, 0.5, 0.75, 0.9, 0.98, 1)))
```

Poni¿ej przedstawiamy rozk³ad czasu rozwi¹zywania zadania w próbce i w ca³ej populacji -- jednoczeœnie prezentujemy gêstoœæ rozk³adu normalnego o œredniej i wariancji odpowiadaj¹cych statystykom naszej zmiennej.

```{r, cache = TRUE}
mean.time <- mean(task_data$time); sd.time <- sd(task_data$time)
sample.mean <- mean(sample_data$time); sample.sd <- sd(sample_data$time)
full.plot <- ggplot(task_data, aes(x = time)) + geom_histogram(aes(y=..density..), binwidth = 10000, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean.time, sd = sd.time), color = "blue", size = 1) + ggtitle("Rozk³ad czasu rozwi¹zywania w ca³ym zbiorze")
sample.plot <- ggplot(sample_data, aes(x = time)) + geom_histogram(aes(y=..density..), binwidth = 10000, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = sample.mean, sd = sample.sd), color = "blue", size = 1) + ggtitle("Rozk³ad czasu rozwi¹zywania w podpróbce")
grid.arrange(full.plot, sample.plot)
rm(full.plot, sample.plot, task_data)
```

Na powy¿szych wykresach widaæ ¿e pod-populacja dobrze oddaje rozk³ad czasu rozwi¹zywania w pe³nej populacji. Równie¿ parametry dla naszej próbki s¹ bardzo zbli¿one do parametrów ca³ej populacji: œrednie dla populacji i pod-populacji wynosz¹ odpowiednio `r mean.time` i `r sample.mean`, a odchylenia standardowe `r sd.time` i `r sample.sd`.

### Reszty modelu wyjœciowego

Teraz wyznaczymy reszty modelu liniowego, który bêdzie punktem wyjœcia w naszej analizie i przedstawimy je na wykresie porównuj¹c z rozk³adem normalnym:

```{r, cache = TRUE}
modelTaskQPosition <- lm(time ~ task + task/Q.nb + position, data = sample_data)
ggplot(data.frame(reszty = modelTaskQPosition$residuals), aes(x = reszty)) + geom_histogram(aes(y=..density..), binwidth = 10000, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean(modelTaskQPosition$residuals), sd = sd(modelTaskQPosition$residuals)), color = "blue", size = 1) + ggtitle("Rozk³ad reszt modelu wyjœciowego")
```

Na powy¿szym wykresie widaæ wyraŸn¹ rozbie¿noœæ rozk³adu reszt wzglêdem rozk³adu normalnego. Jest on silnie prawoskoœny (wspó³czynnik skoœnoœci wynosi `r skewness(modelTaskQPosition$residuals)`, w rozk³adzie normalnym jest to 0) i spiczasty (kurtoza wynosi `r kurtosis(modelTaskQPosition$residuals)`, w rozk³adzie normalnym jest to 3), zatem przed rozpoczêciem modelu powinniœmy wykonaæ odpowiedni¹ transformacjê zmiennej objaœnianej. Rozpatrzymy dwa rodzaje transformacji: Boxa-Coxa oraz logarytmiczn¹ z przesuniêciem.

### Transformacja Boxa-Coxa

Poni¿ej przedstawiamy wykres log-wiarygodnoœci modelu w zale¿noœci od zastosowanej transformacji Boxa-Coxa.

```{r, cache = TRUE}
bc <- boxcox(modelTaskQPosition, plotit = TRUE)
wykladnik <- bc$x[which.max(bc$y)] # optymalny wyk³adnik
```

Optymalny wyk³adnik (spoœród rozpatrywanej siatki wyk³adników) dla tej transformacji wynosi `r wykladnik`, przy czym wyk³adnik ten zale¿y od postaci modelu, wiêc w przypadku problemu z diagnostyk¹ innych wersji modelu na dalszym etapie analizy bêdziemy musieli powróciæ do tej kwestii.

Na poni¿szym wykresie prezentujemy rozk³ad reszt modelu po zastosowaniu tej transformacji oraz gêstoœæ rozk³adu normalnego o parametrach równych statystykom tego rozk³adu.

```{r, cache=TRUE}
modelTaskQPosition_bc <- lm(time^wykladnik ~ task + task/Q.nb + position, data = sample_data)
ggplot(data.frame(reszty = modelTaskQPosition_bc$residuals), aes(x = reszty)) + geom_histogram(aes(y=..density..), binwidth = 10, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean(modelTaskQPosition_bc$residuals), sd = sd(modelTaskQPosition_bc$residuals)), color = "blue", size = 1) + ggtitle("Rozk³ad reszt modelu wyjœciowego po transformacji Boxa-Coxa")
```

Jak widaæ, dopasowanie rozk³adu normalnego do rozk³adu naszej zmiennej po transformacji jest znacznie lepsze ni¿ wczeœniej. Skoœnoœæ jest bliska zera: `r skewness(modelTaskQPosition_bc$residuals)`, natomiast kurtoza wynosi `r kurtosis(modelTaskQPosition_bc$residuals)`, czyli nieznacznie wiêcej ni¿ powinna -- nawet tak niewielka rozbie¿noœæ mo¿e prowadziæ do odrzucenia hipotezy zerowej testu na normalnoœæ rozk³adu:

```{r}
ad.test(modelTaskQPosition_bc$residuals) # test Andersona Darlinga
rm(modelTaskQPosition_bc)
```

Faktycznie odrzucamy hipotezê zerow¹, jednak warto zaznaczyæ, ¿e testy normalnoœci s¹ bardzo restrykcyjne i zwykle prowadz¹ do odrzucenia hipotezy o normalnoœci rozk³adu, szczególnie przy tak du¿ej próbie. Z tego wzglêdu przy ocenie normalnoœci rozk³adu bêdziemy bazowaæ bardziej na porównaniu wykresów rozk³adu oraz wykresów typu QQ.

### Transformacja logarytmiczna z przesuniêciem

Poni¿ej przedstawiamy wykres log-wiarygodnoœci modelu w zale¿noœci od przesuniêcia zastosowanego przed wykonaniem transformacji logarytmicznej.

```{r, cache = TRUE}
lt <- logtrans(modelTaskQPosition, alpha = seq(0.5, 100000, by = 5000), plotit = TRUE)
przesuniecie <- lt[[1]][which.max(lt[[2]])] # optymalne przesuniêcie
```

Optymalne przesuniêcie (spoœród rozpatrywanej siatki przesuniêæ) dla transformacji logarytmicznej wynosi `r przesuniecie`, przy czym zale¿y ono od postaci modelu, wiêc w przypadku problemu z diagnostyk¹ innych wersji modelu na dalszym etapie analizy bêdziemy musieli powróciæ do tej kwestii.

Na poni¿szym wykresie prezentujemy rozk³ad reszt modelu po zastosowaniu tej transformacji oraz gêstoœæ rozk³adu normalnego o parametrach równych statystykom tego rozk³adu.

```{r, cache = TRUE}
modelTaskQPosition_lt <- lm(log(time) ~ task + task/Q.nb + position, data = sample_data)
ggplot(data.frame(reszty = modelTaskQPosition_lt$residuals), aes(x = reszty)) + geom_histogram(aes(y=..density..), binwidth = 0.2, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean(modelTaskQPosition_lt$residuals), sd = sd(modelTaskQPosition_lt$residuals)), color = "blue", size = 1) + ggtitle("Rozk³ad reszt modelu wyjœciowego po transformacji logarytmicznej z przesuniêciem")
```

Jak widaæ, dopasowanie rozk³adu normalnego do rozk³adu naszej zmiennej po transformacji jest lepsze ni¿ bez transformacji, ale wci¹¿ nienajlepsze. Skoœnoœæ jest doœæ niska: `r skewness(modelTaskQPosition_lt$residuals)`, natomiast kurtoza wynosi `r kurtosis(modelTaskQPosition_lt$residuals)`, czyli znacznie wiêcej ni¿ powinna, wiêc nie dziwi nas odrzucenie hipotezy zerowej o normalnoœci rozk³adu:

```{r}
ad.test(modelTaskQPosition_lt$residuals) # test Andersona Darlinga
rm(modelTaskQPosition_lt)
```

### Porównanie wyników

Spoœród dwóch rozpatrzonych rodzajów transformacji musimy wybraæ jedn¹. W tym celu porównamy ich wykresy QQ:

**Optymalna transformacja Boxa-Coxa**

```{r, cache = TRUE}
modelTaskQPosition_bc <- lm(time^wykladnik ~ task + task/Q.nb + position, data = sample_data)
qqPlot(modelTaskQPosition_bc$residuals)
aic_bc <- AIC(modelTaskQPosition_bc, k = 2)
rm(modelTaskQPosition_bc)
```

**Optymalna transformacja logarytmiczna z przesuniêciem**

```{r, cache = TRUE}
modelTaskQPosition_lt <- lm(log(time + przesuniecie) ~ task + task/Q.nb + position, data = sample_data)
qqPlot(modelTaskQPosition_lt$residuals)
aic_lt <- AIC(modelTaskQPosition_lt, k = 2)
rm(modelTaskQPosition_lt)
```

Na podstawie powy¿szych wykresów stwierdzamy, ¿e ¿adna z transformacji nie rozwi¹zuje problemu nienormalnoœci reszt. Wielkoœæ rozbie¿noœci jest podobna dla obu transformacji, jednak wydaje siê dotyczyæ mniejszej liczby kwantyli w przypadku transformacji logarytmicznej z przesuniêciem. Ponadto, kryterium informacyjne Akaike'a wynosi `r aic_bc` dla pierwszego modelu, a `r aic_lt` dla drugiego, czyli wyraŸnie wskazuje na drugi z nich (podobnie jest z kryterium bayesowskim Schwarza). Z tego wzglêdu decydujemy siê na transformacjê logarytmiczn¹ z przesuniêciem `r przesuniecie`.

### Zale¿noœci pomiêdzy zmienn¹ objaœnian¹ i objaœniaj¹cymi

Przed budow¹ modelu warto zastanowiæ siê nad sensownoœci¹ w³¹czenia do niego poszczególnych zmiennych. W tym celu przyjrzymy siê bli¿ej rozk³adowi zmiennej objaœnianej w podziale na grupy ze wzglêdu na wartoœci kolejnych zmiennych objaœniaj¹cych (wszystkie s¹ jakoœciowe, st¹d podzia³ na grupy).

Na wszystkich wykresach na niebiesko zaznaczamy globaln¹ œredni¹ zmiennej objaœnianej, a na czerwono œredni¹ w grupach.

```{r, fig.heigh = 12, cache = TRUE}
ggplot(sample_data, aes(y = time^wykladnik, x = task)) + geom_boxplot() + geom_hline(aes(yintercept = mean(sample_data$time^wykladnik)), color = "blue", size = 2) + coord_flip() + stat_summary(fun.y = mean, shape = 16, color = 'red', size = 2, geom = 'point') + ggtitle("Rozk³ad zmiennej objaœnianej w grupach wg zmiennej task")
```

Na powy¿szym wykresie widzimy, ¿e wystêpuje wyraŸne zró¿nicowanie rozk³adu (a przede wszystkim jego œredniej) zmiennej objaœnianej w zale¿noœci od rozwi¹zywanego zadania, czego mo¿na siê by³o spodziewaæ bior¹c pod uwagê to, ¿e zadania ró¿ni¹ siê od siebie trudnoœci¹ itp.

```{r, cache = TRUE}
ggplot(sample_data, aes(y = time^wykladnik, x = Q.nb)) + geom_boxplot() + geom_hline(aes(yintercept = mean(sample_data$time^wykladnik)), color = "blue", size = 2) + coord_flip() + stat_summary(fun.y = mean, shape = 16, color = 'red', size = 2, geom = 'point') + ggtitle("Rozk³ad zmiennej objaœnianej w grupach wg zmiennej Q.nb")
```

Na powy¿szym wykresie widzimy, ¿e zró¿nicowanie rozk³adu zmiennej objaœnianej w zale¿noœci od (skorygowanego) numeru podpunktu nie jest zbyt du¿e. Mo¿emy zatem wstêpnie podejrzewaæ, ¿e nie wystêpuje zjawisko znudzenia/zmêczenia zadaniem ani wzrostu trudnoœci kolejnych podpunktów.

```{r, cache = TRUE}
ggplot(sample_data, aes(y = time^wykladnik, x = position)) + geom_boxplot() + geom_hline(aes(yintercept = mean(sample_data$time^wykladnik)), color = "blue", size = 2) + coord_flip() + stat_summary(fun.y = mean, shape = 16, color = 'red', size = 2, geom = 'point') + ggtitle("Rozk³ad zmiennej objaœnianej w grupach wg zmiennej position")
```

Na powy¿szym wykresie widzimy, ¿e zró¿nicowanie rozk³adu zmiennej objaœnianej w zale¿noœci od pozycji zadania w kwestionariuszu przejawia siê przesuniêciem tego rozk³adu w stronê ni¿szych wartoœci w przypadku pozycji -1, która mo¿e oznaczaæ coœ nietypowego (takich obserwacji jest zaledwie 16 tysiêcy w ca³ym zbiorze wobec prawie miliona w przypadku pozosta³ych wartoœci tej zmiennej) -- `BOOKID` dla wszystkich obserwacji, dla których `position == -1` przyjmuje wartoœæ `rm` zamiast liczby, jak we wszystkich pozosta³ych przypadkach.

Podsumowuj¹c, spodziewamy siê istotnoœci wszystkich zmiennych objaœniaj¹cych, przy czym najwa¿niejsza wydaje siê byæ zmienna `task`, wiêc w³¹czymy j¹ do modelu jako pierwsz¹, co bêdzie szczególnie wa¿ne przy analizie wariancji (zbadamy oczywiœcie alternatywne warianty).

## Budowa modelu

### Sekwencyjne testy istotnoœci zmiennych

Pierwszym krokiem przy budowie modelu liniowego jest wybór zmiennych objaœniaj¹cych. Na tym etapie analizy naszym zadaniem jest rozpatrzenie trzech zmiennych jako objaœniaj¹cych: zadanie, podpunkt i pozycja w kwestionariuszu. Nale¿y jednak zastanowiæ siê w jakiej postaci do modelu powinna wejœæ zmienna podpunkt. W³¹czenie jej jako osobnej zmiennej bêdzie oznacza³o, ¿e kolejnoœæ podpunktów ma znaczenie dla czasu ich rozwi¹zywania. Z drugiej strony, moglibyœmy w³¹czyæ podpunkt jako zmienn¹ zagnie¿d¿on¹ w zadaniu, co odzwierciedla³oby zró¿nicowanie podpunktów w zadaniach, niekoniecznie zwi¹zane z ich kolejnoœci¹.

Poni¿ej szacujemy parametry w obu wersjach:

```{r}
modelTaskQPosition <- lm(log(time + przesuniecie) ~ task + Q.nb + position, data = sample_data)
aic1 <- AIC(modelTaskQPosition, k = 2); bic1 <- BIC(modelTaskQPosition)
anova(modelTaskQPosition)
modelTaskQPosition <- lm(log(time + przesuniecie) ~ task + task:Q.nb + position, data = sample_data)
aic2 <- AIC(modelTaskQPosition, k = 2); bic2 <- BIC(modelTaskQPosition)
anova(modelTaskQPosition)
```

W obu modelach wszystkie zmienne s¹ isototne przy dowolnym sensownym poziomie istotnoœci. Kryterium informacyjne Akaike'a wynosi  `r aic1` dla pierwszego i `r aic2` dla drugiego modelu, a bayesowskie Schwarza `r bic1` i `r bic2`, odpowiednio. Oba kryteria przyjmuj¹ ni¿sze wartoœci dla modelu z interakcj¹, zatem ten model bêdziemy rozwa¿aæ w dalszej analizie.

Teraz przeprowadzimy sekwencyjne testy ³¹cznej istotnoœci zmiennych rozpatruj¹c pozosta³e mo¿liwe kolejnoœci w³¹czania tych zmiennych do modelu:

```{r, cache = TRUE}
anova(lm(log(time + przesuniecie) ~ task:Q.nb + task + position, data = sample_data))
anova(lm(log(time + przesuniecie) ~ position + task + task:Q.nb, data = sample_data))
anova(lm(log(time + przesuniecie) ~ task + position + task:Q.nb, data = sample_data))
anova(lm(log(time + przesuniecie) ~ task:Q.nb + position + task, data = sample_data))
anova(lm(log(time + przesuniecie) ~ position + task:Q.nb + task, data = sample_data))
```

**Wniosek:** Na podstawie powy¿szych wyników stwierdzamy, ¿e przy ka¿dym rozs¹dnym poziomie istotnoœci odrzucamy hipotezê zerow¹, ¿e model bez jednej ze zmiennych jest lepszy ni¿ model z ni¹, niezale¿nie od kolejnoœci w³¹czania zmiennych do modelu. Oznacza to, ¿e wszystkie zmienne s¹ wa¿ne i powinny zostaæ w modelu.

### Oszacowania parametrów

Oszacowania parametrów naszego modelu s¹ nastêpuj¹ce:

```{r}
summary(modelTaskQPosition)
rm(modelTaskQPosition)
```

Jak widaæ, testy istotnoœci poszczególnych poziomów zmiennych objaœniaj¹cych (w tym modelu, gdy¿ to nie s¹ testy sekwencyjne) wskazuj¹ na istotnoœæ wszystkich poza jednym: wygl¹da na to, ¿e œredni czas rozwi¹zywania zadania M474 nie ró¿ni siê istotnie od czasu rozwi¹zywania zadania bazowego, czyli M982. Poza tym mo¿emy stwierdziæ, ¿e ró¿ne poziomy naszych zmiennych objaœniaj¹cych w sposób istotny ró¿nicuj¹ œredni czas rozwi¹zywania zadania.

### Testy post-hoc

Nastêpnym krokiem w naszej analizie jest wykonanie testów post-hoc.

#### Test t

Po wykonaniu testów $t$ porównuj¹cych œrednie parami dla kazdej ze zmiennych objaœniaj¹cych stwierdzamy, ¿e przy poziomie istotnoœci 0.05 ró¿nice miêdzy œrednimi s¹ nieistotne dla:

- **zmienna task:** œredni czas rozwi¹zywania nie ró¿ni siê zbytnio pomiêdzy niektórymi parami zadañ (w pe³nej tabeli p-wartoœci zdarzaj¹ siê nawet wartoœci 1), jednak jest ich mniejszoœæ (wszystkich par jest `r length(table(sample_data$task))*(length(table(sample_data$task))-1)/2`). Poni¿sza tabela obrazuje pary zadañ, pomiêdzy którymi ró¿nice s¹ nieistotne:

```{r}
df1 <- pairwise.t.test(log(sample_data$time + przesuniecie), sample_data$task)$p.value
df <- as.data.frame(which(df1 > 0.05, arr.ind = TRUE))
df$col <- factor(df$col, levels = 1:length(colnames(df1)), labels = colnames(df1))
df$row <- factor(df$row, levels = 1:length(colnames(df1)), labels = colnames(df1))
rownames(df) <- 1:nrow(df)
t(df) # wiersze row i col daj¹ pary, dla których ró¿nice sa nieistotne
```

- **zmienna Q.nb:** wszystkie podpunkty ró¿ni¹ siê istotnie pod wzglêdem œredniego czasu rozwi¹zywania zadania

```{r}
pairwise.t.test(log(sample_data$time + przesuniecie), sample_data$Q.nb)$p.value
```

- **zmienna position:** wszystkie pozycje w kwestionariuszu ró¿ni¹ siê istotnie pod wzglêdem œredniego czasu rozwi¹zywania zadania

```{r}
pairwise.t.test(log(sample_data$time + przesuniecie), sample_data$position)$p.value
```

#### Test Tukey'a

Nastêpnie wykonamy test post-hoc Tukey'a. Niestety, ze wzglêdu na liczbê parametrów zwi¹zanych z zagnie¿d¿on¹ interakcj¹ zmiennej `task` ze zmienn¹ `Q.nb` posiadana przez nas moc obliczeniowa nie pozwala na wykonanie tego testu dla naszego modelu, dlatego wykonujemy go dla modelu ze zmienn¹ `Q.nb` bez interakcji, co jest pewnym uproszczeniem.

```{r, eval = FALSE}
print(plot(TukeyHSD(aov(log(time + przesuniecie) ~ task + Q.nb + position, data = sample_data), which = "task"), las = 1))
```

Na poni¿szym wykresie widzimy wyniki testu Tukey'a dla zmiennej `task` (dalsze wyd³u¿anie tego wykresu niewiele pomaga, dlatego zostawiliœmy go w tej postaci). Widaæ, ¿e ró¿nice miêdzy niektórymi zadaniami jest nieistotna, ale jest ich zdecydowanie mniej ni¿ istotnych ró¿nic (przedzia³y ufnoœci s¹ bardzo w¹skie ze wzglêdu na du¿¹ liczbê obserwacji).

![](Czesc1_plot1.png)

```{r, cache = TRUE}
plot(TukeyHSD(aov(log(time + przesuniecie) ~ task + Q.nb + position, data = sample_data), which = c("Q.nb", "position")), las = 1)
```

Na obu poni¿szych wykresach widaæ, ¿e przy poziomie istotnoœci 0.05 wszystkie pary kategorii ka¿dej ze zmiennych `Q.nb` i `position` ró¿ni¹ siê pomiêdzy sob¹.

## Wnioski

Na tym etapie analizy stwierdzamy, ¿e przy tym zestawie rozwa¿anych zmiennych objaœniaj¹cych wszystkie s¹ istotne w objaœnianiu zmiennoœci czasu rozwi¹zywania zadania.

Optymaln¹ dla naszego modelu transformacj¹ zmiennej objaœnianej jest transformacja logarytmiczna po przesuniêciu, przy czym nale¿y pamiêtaæ, ¿e analizê wykonujemy na podpróbce zbioru danych wybieraj¹c co czwart¹ szko³ê.

Testy post-hoc wskazuj¹ na istotne ró¿nice miêdzy œrednimi czasami rozwi¹zywania zadañ po transformacji miêdzy wiêkszoœci¹ grup obserwacji ze wzglêdu na kategorie wybranej zmiennej objaœnianej.

# Za³¹czniki

Podczas analizy nienormalnoœci rozk³adu reszt natrafiliœmy na zró¿nicowanie kszta³tu rozk³adu zmiennej objaœnianej w podziale na grupy ze wzglêdu na zadanie, co prezentujemy poni¿ej:

```{r, cache = TRUE}
normal.task <- sample_data[sample_data$item_short == "M936Q02", ]
nonnormal.task <- sample_data[sample_data$item_short == "M954Q01", ]
normal.plot <- ggplot(normal.task, aes(x = time^wykladnik)) + geom_histogram(aes(y=..density..), binwidth = 3, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean(normal.task$time^wykladnik), sd = sd(normal.task$time^wykladnik)), color = "blue", size = 1) + ggtitle("Zadanie o normalnym czasie rozwi¹zywania: M936Q02, pvalue 1.14e-01") 
nonnormal.plot <- ggplot(nonnormal.task, aes(x=time^wykladnik)) + geom_histogram(aes(y=..density..), binwidth = 3, color = "black", fill = "white") + stat_function(fun = dnorm, args = list(mean = mean(nonnormal.task$time^wykladnik), sd = sd(nonnormal.task$time^wykladnik)), color = "blue", size = 1) + ggtitle("Zadanie o nienormalnym czasie rozwi¹zywania: M954Q01, pvalue 3.70e-24") 
grid.arrange(normal.plot, nonnormal.plot)
```

Nienormalnoœæ rozk³adów jest na ogó³ powodowana wysok¹ kurtoz¹ -- rozk³ady s¹ zbyt spiczaste jak na rozk³ad normalny o parametrach estymowanych z danych. Ponadto, z wykresów widaæ ¿e w wielu zadaniach populacja jest bardzo niejednorodna. Poza wspomnianymi ju¿ wczeœniej uczniami "wytrwa³ymi", powoduj¹cymi d³ugie ogony, w niektorych zadaniach widaæ równie¿ wyraŸnie populacjê "geniuszy", którzy rozwi¹zuj¹ zadania o wiele szybciej. Histogramy wskazuj¹ ¿e populacjê "geniuszy" równie¿ cechuje normalny czas rozwi¹zywania zadania. 

Rozk³ad empiryczny jest najprawdopodobniej mieszank¹ trzech rozk³adów, w tym dwóch rozk³adów normalnych odpowiadaj¹cych "geniuszom" i uczniom "typowym", oraz nieznanego rozk³adu dla uczniów "wytrwa³ych". Mo¿na przypuszczaæ, ze po wyodrêbnieniu poszczególnych populacji np. algorytmem EM, otrzymalibyœmy po transformacji Boxa-Coxa normalne czasy rozwi¹zywania zadañ.

