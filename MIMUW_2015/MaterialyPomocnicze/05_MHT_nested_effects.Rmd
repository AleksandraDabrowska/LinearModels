---
title: "Multiple hypothesis testing problem and Nested effects in ANOVA"
author: "Przemyslaw Biecek"
date: "Linear models with fixed and random effects"
output: 
  html_document:
    toc: TRUE
---

# Comments related to the project

1. Problems with diagnostic. Either you have chosen different method for each gene that did not pass diagnostic or you have ignored the outcomes from diagnostic tests.

Consider following scenario. 10000 samples of length 2000 and we are going to test for normality. 

```{r}
set.seed(1313)

M <- 10000
n <- 2000
mat <- matrix(rnorm(M*n), M, n)
pvals <- apply(mat, 1, function(x) shapiro.test(x)$p.value)

table(pvals < 0.05)
```

Now consider that we round the values up to one digit after decimal point. 

Guess how many samples will pass the test.

```{r}
mat <- round(mat, 1)
pvals <- apply(mat, 1, function(x) shapiro.test(x)$p.value)

table(pvals < 0.05)
```

How we should check problems with normality?

```{r}
library(nortest)

D <- apply(mat, 1, function(x) lillie.test(x)$statistic)
hist(D, 100)

```

2. Lack of detailed (and graphical) inspection of identified signals.

There is a lot of plots that may help us to understand what is happening in the data. Use them frequently to justify/validate results from tests!

```{r}
cancers <- rep(c("Breast", "Ovarian", "Lung"), each=10)
treatments <- rep(c("Chemo", "Radio", "Mixed"), each=10)
df <- merge(cancers, treatments)
df$z <- rnorm(nrow(df)) + ifelse(df$x == "Breast" & df$y == "Radio", 3, 0)

#
# boxplots()
par(mar=c(2,8,2,2))
boxplot(z~x+y, df, horizontal=TRUE, las=1)

interaction.plot(df$x, df$y, df$z)
interaction.plot(df$y, df$x, df$z)

unclass(by(df$z, list(df$x, df$y), mean))

plot.design(z~x+y, data=df)

model <- aov(z~x+y, data=df)
plot(TukeyHSD(model, "x"), las=1)

```


# Multiple hypothesis testing

## Family wise error rate

Consider the following scenario.

We have H hypotheses in one-way ANOVA. All are true. How to choose the threshold / significance level for testing.

FWER is the probability that we reject at lease one true null hypothesis.

FWER = P(V>=0)

```{r}
M <- 1000  # replicates
H <- 10   # number of hypotheses
n <- 20   # sample size

allHyp <- replicate(M, {
  pvals <- replicate(H, {
    x <- rnorm(n)
    y <- rnorm(n)
    df <- data.frame(z=c(x,y), g = rep(1:2, each=n))
    
    summary(aov(z~g, df))[[1]][1,5]
  })
  min(pvals) > 0.05  
})

# what is the probability that we reject one or more hypotheses

mean(allHyp)

# How it looks like as a function of alpha?

allPs <- replicate(M, {
  pvals <- replicate(H, {
    x <- rnorm(n)
    y <- rnorm(n)
    df <- data.frame(z=c(x,y), g = rep(1:2, each=n))
    
    summary(aov(z~g, df))[[1]][1,5]
  })
  min(pvals)
})

cutoffs <- seq(0,0.1,0.001)
power <- sapply(cutoffs, function(cutoff) {
  mean(allPs < cutoff)
})

plot(cutoffs, power, ylab="FWER", las=1)
abline(v=0.05)
abline(h=0.05)

# Here is where adjusted p-values come from

adjAllPs <- replicate(M, {
  pvals <- replicate(H, {
    x <- rnorm(n)
    y <- rnorm(n)
    df <- data.frame(z=c(x,y), g = rep(1:2, each=n))
    
    summary(aov(z~g, df))[[1]][1,5]
  })
  min(p.adjust(pvals, method = "holm"))
})

cutoffs <- seq(0,0.1,0.001)
power <- sapply(cutoffs, function(cutoff) {
  mean(adjAllPs < cutoff)
})

plot(cutoffs, power, ylab="FWER", las=1)
abline(v=0.05)
abline(h=0.05)

```

## False discovery rate

Consider the following scenario.

We have H hypotheses in one-way ANOVA. First 50% are true 50% are false. We would like to have small fraction of false positives in all positive tests.

FDR is the expected proportion of rejected true null hypotheses in all rejected hypotheses.

FDF = E(V/R | R>0)P(R>0)

```{r}
M <- 1000  # replicates
H <- 10   # number of hypotheses
n <- 20   # sample size

allHyp <- replicate(M, {
  pvals <- sapply(1:H, function(h) {
    x <- rnorm(n)
    y <- rnorm(n) + ifelse(h<6, 0, 0.4)
    df <- data.frame(z=c(x,y), g = rep(1:2, each=n))
    
    summary(aov(z~g, df))[[1]][1,5]
  })
  sum(pvals[1:(H/2)] < 0.05)/sum(pvals < 0.05)
})

# what is the probability that we reject one or more hypotheses

allHyp[is.nan(allHyp)] <- 0
mean(allHyp[!is.nan(allHyp)])

# Here is where adjusted p-values come from

adjAllPs <- replicate(M, {
  pvals <- sapply(1:H, function(h) {
    x <- rnorm(n)
    y <- rnorm(n) + ifelse(h<6, 0, 0.4)
    df <- data.frame(z=c(x,y), g = rep(1:2, each=n))
    
    summary(aov(z~g, df))[[1]][1,5]
  })
  pvals <- p.adjust(pvals, method = "fdr")
  sum(pvals[1:(H/2)] < 0.05)/sum(pvals < 0.05)
})

adjAllPs[is.nan(adjAllPs)] <- 0
mean(adjAllPs)

```

# Issues related to two-way ANOVA

Again, let us consider two-way ANOVA with two crossed effects. Bot factor variables have three levels. There are 9 averages in total.

```{r}
cancers <- rep(c("Breast", "Ovarian", "Lung"), each=10)
treatments <- rep(c("Chemo", "Radio", "Mixed"), each=10)
df <- merge(cancers, treatments)
df$z <- rnorm(nrow(df)) + ifelse(df$x == "Breast" & df$y == "Radio", 3, 0)
```

What hypotheses can we test? What test can we perform?

## Main effects

```{r}
colnames(df) <- c("cancers", "treatments", "z")



model0 <- lm(z~1, data=df)
modelC <- lm(z~cancers, data=df)
modelCT <- lm(z~cancers+treatments, data=df)
modelCTi <- lm(z~cancers*treatments, data=df)

anova(modelC)
anova(modelC, model0)

anova(modelCT)

anova(modelCT, model0)

anova(modelCTi, modelCT)
anova(modelCTi, modelC)
```

What about effects for single group?

```{r}
summary(modelCTi)
```

# Comments related to the home work 4

Let's discuss following homeworks:

* Mose homeworks are limited just to histograms. Try to use more graphs to justify/validate your results.
(`Katarzyna_Kanska_h4.html`)

* There are just few homeworks with power not equal to 1. Hoever here power of the size 0.25 should rise questions.
(`agnieszka_sitko_04.html`)

* More explanations. One should point what are the expectations.
(`krzysztof_rutkowski_4.Rmd`)

* All of you have used histograms to present the distribution for p-value. What about other characterisitcs like ecdf?

# Home work for 5 XI 2015

Read the chapter 2.4 from ,,Analiza danych z programem R, Modele liniowe mieszane'' or in English (https://www.ma.utexas.edu/users/mks/384E07/nestedfactors.pdf + how to do this in R http://www.stat.wisc.edu/courses/st333-larget/chimps.pdf).

Now, imagine following scenario.

You have data for n patients. For each patient you have his/her blood pressure, gender and type of diabetes (here, let's assume that there are three types of diabetes: pre, 1 and 2).
Let assume that male have blood pressure is higher than female (on average) and the difference is delta1 = 1. Then let's assume that nested effect of diabetes is delta2= (0, 0, 0.5) for male and delta3=(0, 0, 1) for female.

Our goal is to find sample size, for which the test for nested effect (only effect of diabetes) has power 0.8.

* Create a simulation study in which for a given n - sample size you will calculate power for hypothesis H0: delta2=0 and delta3=0. 
* Choose the smallest n for which power is not smaller than 0.8. I.e. what is the minimal number of patients that allow to detect effect of the size (0,0,0.5,0,0,1) with probability larger than 80%.


