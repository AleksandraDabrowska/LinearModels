---
title: "Untitled"
author: "Emilia Pompe"
date: "Saturday, January 16, 2016"
output: html_document
---
## Emilia Pompe
## Saturday, January 16, 2016

## Introduction
Let us download and take a look at the dataset
```{r}
library(ade4)
library(nlme)
library(ggplot2)
library(geoR)

spdata <- read.table("http://www.ats.ucla.edu/stat/r/faq/thick.csv", header = T, sep = ",")
head(spdata)
```

Among others, it contains also the variables 'thick' and soil'. The goal of this short report is to test whether there is any relation between these two variables, where 'thick' is the independent variable and 'soil' is the dependent variable. Let us take a look at the scatterplot of these two variables.

```{r, message=FALSE, warning=FALSE}
ggplot(spdata, aes(x=soil, y=thick)) + geom_point()+stat_smooth(method="lm")
```

There is some pattern between the variables (increasing function), but linear fit does not seem to be the best one, as there is a lot of variability around the regression line.

## Simple linear regression model with one dependent variable 
```{r, message=FALSE, warning=FALSE}
model.simple <- lm(thick ~ soil, data = spdata)
summary(model.simple)
```
At the significance level equal to 0.05 we would consider tha variable as significant. This significance level seems fairly reasonable as the sample size is small (only 75 observations). Nevertheless, the model does not seem to be well-fitted. The p-value is 0.01111, so at the significance level 0.01 (which could also be considered as a reasonable choice), the variable would be insignificant. What is more, the R-squared is only 0.0850 and the assumption of normality of standardised residuals is violated, what is presented in the chart below:
```{r, message=FALSE, warning=FALSE}
qqnorm(rstandard(model.simple))
qqline(rstandard(model.simple), col="red", add=TRUE)
```

This, together with graphical analysis presented in the Introduction, leads to a conclusion that this a bad choice for the model and we proably should not make inference based on it. This is one of the reasons why we want to consider a slightly more complex model, taking into account also the spatial structure.

## Model which takes into account spatial structure of measurements (variables east and north).

```{r, message=FALSE, warning=FALSE}
model.lin <- lme(thick ~ soil, correlation = corLin(form = ~ east + north), random= ~1|dummy, method="ML", data=spdata)
model.gaus <- lme(thick ~ soil, correlation = corGaus(form = ~ east + north), random= ~1|dummy, method="ML", data=spdata)
model.exp <- lme(thick ~ soil, correlation = corExp(form = ~ east + north), random= ~1|dummy, method="ML", data=spdata)
model.spher <- lme(thick ~ soil, correlation = corSpher(form = ~ east + north), random= ~1|dummy, method="ML", data=spdata)
model.ratio <- lme(thick ~ soil, correlation = corRatio(form = ~ east + north), random= ~1|dummy, method="ML", data=spdata)
```

Let us consider three well known criterias to compare the models above: AIC, BIC, logLik. Let us recall that the AIC criterion (and BIC) tells us to choose the model with the lowest AIC value (and BIC value, accordingly), whereas the logLik criterion tells us to choose model with the highest log-likelihood value. I calculated the values 

```{r, message=FALSE, warning=FALSE}
my.models <- list(model.lin=model.lin, 
                  model.gaus=model.gaus, 
                  model.exp=model.exp, 
                  model.spher=model.spher,
                  model.ratio=model.ratio)
model.crit <- as.data.frame(matrix(NA, ncol=3, nrow=length(my.models)))
colnames(model.crit) <- c("AIC", "BIC", "logLik")
rownames(model.crit) <- names(my.models)
 for (i in 1:length(my.models)){
  model.crit[i,] <- c(AIC(my.models[[i]]), BIC(my.models[[i]]), logLik(my.models[[i]]))
}

model.crit
```

The data frame above shows model.ration outperformed the remaining ones. Let us also take a look at different fitting lines (for the same correlation structures as the ones used above). 
```{r, message=FALSE, warning=FALSE}
variogram <- variog(coords = spdata[,2:3], data = spdata$thick)
lin.fit <- variofit(variogram, cov.model="linear", vario=variogram)
gaus.fit <- variofit(variogram, cov.model="gaussian", ini.cov.pars=c(1, 1))
exp.fit <- variofit(variogram, cov.model="exponential", ini.cov.pars=c(1, 1))
spher.fit <- variofit(variogram, cov.model="spherical", ini.cov.pars=c(1, 1))
ratio.fit <- variofit(variogram, cov.model="cauchy", ini.cov.pars=c(1, 1), fix.kappa = TRUE, kappa=2) # ratio
```
```{r, message=FALSE, warning=FALSE}
plot(variogram, type = "b", main="Variogram for spdata") 
lines(lin.fit, col="pink", lwd=2)
lines(gaus.fit, col="red", lwd=2)
lines.variomodel(exp.fit, col="green", lwd=2)
lines.variomodel(spher.fit, col="blue", lwd=2)
lines.variomodel(ratio.fit, col="orange", lwd=2)
```

Indeed the orange line (which corresponds to the corRatio) gives the best fit. Let us then take a look at the summary of the chosen model:
```{r, message=FALSE, warning=FALSE}
summary(model.ratio)
```
In this model tha variable soil is not significant

Let us also consider a formal test (Mantel), it is used for testing significance of correlation between two distance matrices
```{r, message=FALSE, warning=FALSE}
N <- 10000
set.seed(7)
dist1 <- dist(spdata[,2:3]) # east and north
dist2 <- dist(spdata$thick)
mantel.rtest(dist1, dist2, nrepet = N)
```

The p.value in the Mantel test turned out to be very low. This indicates that the spatial structure was significant. 

## Conclusions
After including the spatial structure it turned out that the variable soil is not significant and 'thick' should not be explained by using it. The study shows that not taking into account the spatial structure when it is substantial  may lead to incorrect inference - in this example 'soil' was significant at the significance level 0.05 in the simple linear regression model with one dependent variable.
