---
title: "Praca domowa 3"
author: "Piotr Obarski"
date: "Modele liniowe i mieszane"
output: 
  html_document:
  toc: TRUE
---
### Simulate two datasets, 1000 observations each. Create the first dataset in a way to pass all diagnostic plots (so, all assumptions are valid). Create the second dataset in order to fail with at least 3 diagnostic datasets (e.g. with high Cook distances, non homogeneous variance of residuals, so on).
### Show diagnostic plots for both simulated datasets.
Po wygenerowaniu danych, na wykresach diagnostycznych będę sprawdzać, czy testy diagnostyczne są spełnione, więc od razu zrobię 1. i 2. punkt z pracy domowej.


```{r}
library(ggplot2)
library(lmtest)

x1<-c(1:1000)
y1<-rnorm(1000)
dataset1<-data.frame(x1,y1)
model<-lm(y1~x1, data=dataset1)
plot(y1~x1, data=dataset1)
plot(model, which=1:6)
model$residuals[1:20]
```
Widać na wykresach diagnostycznych, że model jest dobry.
</br>

Żeby wygenerować drugi zbiór danych, staram się zrobić coś, żeby zależność nie była liniowa.
```{r}
x2<-x1
y2<-0
y2[1:500]<-(runif(500, 1, 100)+rnorm(500)*2)*x2[1:500]
y2[501:800]<- -runif(300, 1, 100)+rnorm(300)*40
y2[801:1000]<- runif(200)+rnorm(200)
y2[500]<--2000
y2[650]<- -1000
dataset2<-data.frame(x2,y2)
model2<-lm(y2~x2, data=dataset2)
plot(y2~x2, data=dataset2)
plot(model2, which=1:6)
```
</br>
Na wykresach widać, że rzeczywiście nie ma zależności liniowej, a wykresy diagnostyczne potwierdzają tezę, że model jest zły.
Np. wykres Normal Q-Q jest bardzo odległy od idealnego, na wykresie Residuals vs Fitted, widać pewien trend, zatem wariancja reszt nie jest jednorodna, a na Residuals vs Levrage widać, że niektóre obserwacje mają znacząco większe znaczenie niż zdecydowana większość z nich.
Jeszcze zrobię wykresy diagnostyczne obok siebie, żeby je porównać.

```{r}
par(mfrow=c(1,2))
for(i in 1:6){
  plot(model, which=i)
  plot(model2, which=i)
}
par(mfrow=c(1,1))
```

### Choose three tests for model diagnostic (note, you should not choose the same three tests as other students. If your Submission will have same diagnostic tests as other already submitted home work then your homework will be rejected. )
Sprawdzę:</br>
* normalność standaryzowanych reszt </br>
* liniowość testem Rainbow </br>
* homogeniczność wariancji testem Harrisona-McCabe'a </br>

### For each test create two simulated datasets. One that passes the given test and one that does not (e.g. simulate data with heterogeneous variance)
### Present results from diagnostic tests, show p-values for both datasets.

Do testowania normalności reszt użyję zbiorów danych z pierwszej części zadania.

```{r}
shapiro.test(rstandard(model))
shapiro.test(rstandard(model2))
```

Widać, że p-value w pierwszym przypadku jest duże, w drugim małe, co oznacza, że pierwszy test został pomyślnie zakończony, w przeciwieństwie do drugiego.

W teście Harrisona-McCabe'a użyję tych samych danych co powyżej, jednak w dataset2 zamienię zmienną objaśnianą ze zmienną objaśniającą.

```{r}
hmctest(y1~x1, order.by=~x1, data = dataset1, plot=TRUE)
hmctest(x2~y2, order.by=~y2, data = dataset2, plot=TRUE)
```
W pierwszym teście wysoka wartość p-value sugeruje, że wariancje epislonów są homogeniczne, w drugim wręcz przeciwnie.

Teraz testuję liniowość testem Rainbow. Za zbiór danych który ma przejść test przyjmuję dataset1. Lekko zmodyfikuję zbiór dataset2 i on będzie tym, który testu nie przejdzie.
```{r}
dataset2$y2[200:500]<- -dataset2$y2[200:500]
plot(y2~x2, data=dataset2)
raintest(y1~x1, order.by=~x1, data = dataset1)
raintest(y2~x2, order.by=~x2, data = dataset2)
```
Rzeczywiście wartości p-value potwierdzają, że się dzieje tak jak zapowiedziałem.
