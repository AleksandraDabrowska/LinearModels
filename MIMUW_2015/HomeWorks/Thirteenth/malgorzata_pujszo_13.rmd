---
title: "Homework 13"
author: "Ma³gorzata Pujszo"
date: "Wednesday, January 20, 2016"
output: 
  html_document:
    toc: true
---

##Dataset

We will work with gathered data about homeworks. In data frame "homeworks" we have information about lines of report for each student in each week of the semester. Our goal is to find out what explains Lines variable.

Let's first look at our dataset.

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(lattice)
library(lme4)
library(MASS)
library(knitr)
homeworks <- read.table("C:/Users/Gosia/Documents/matma/R/Modele Liniowe i Mieszane/zadania domowe/homeworks.csv", header=TRUE, sep=";")
homeworks$week <- factor(homeworks$Week)
homeworks$Student <- factor(homeworks$Student)
head(homeworks)
```

##Graphical analysis

The plot presents relation between Lines and Week variables.

```{r}
ggplot(homeworks, aes(x=Week, y=Lines)) + geom_point() + geom_smooth()
```

Blue line suggests that the relatio between Week and Lines is not linear. It looks more as quadratic. Let's see what happens if we include effects of each Student. 

```{r}
panel.with.square <- function(...){
  nx = list(...)$x
  ny = list(...)$y
  cc = lm(ny~nx+I(nx^2))$coef
  panel.xyplot(...)
  panel.curve(x^2*cc[3]+x*cc[2]+cc[1], from=min(nx), to=max(nx), col="red")
}

xyplot(Lines ~ Week | Student, homeworks, type = c("g","p","r"), pch=19, panel = panel.with.square)
```

There are a few observations based on the plot: \n
  * Students differ from each other so we should include this variable in the model \n
  * some people submitted very small number of homeworks \n
  * quadratic realtion seems to be a better fit \n

##Modelling

I will treat Week as a fixed effect and Student as random. Since the quadratic relation might be a better fit, let's start from models taking it into accout.

###Testing random effects

```{r, warning=FALSE, message=FALSE}
model1 <- lmer(Lines ~ Week + I(Week^2) + (Week + I(Week^2)|Student), data=homeworks, REML=F)
model2 <- lmer(Lines ~ Week + I(Week^2) + (Week|Student), data=homeworks, REML=F)
anova(model1, model2)
```
  
p-value suggests that second order polynomial in the random part is not significant. 
What about the slope in the random part?

```{r}
model3 <- lmer(Lines ~ Week + I(Week^2) + (1|Student), data=homeworks, REML=F)
anova(model2, model3)
```

It also turned out to be insignificant. Maybe the effect of Student is not significant at all?

```{r}
model4 <- lm(Lines ~ Week + I(Week^2), data=homeworks)
anova(model3, model4)
```

Student variable seems to be important.

###Testing fixed effects

In this section I checked significance of fixed effects (second order polynomial).

```{r}
model5 <- lmer(Lines ~ Week + (1|Student), data=homeworks, REML=F)
anova(model3, model5)
```

Second order polynomial of Week seems to be important.

Consequently, I chose a model3 as the best one.

###Assumptions

####Residuals

Firstly, I examined the residuals' normality.

```{r}
qplot(sample = residuals(model3, scaled=TRUE), stat="qq") + geom_abline(intercept=0, slope=1, colour="red", size=1) + ggtitle("Normal Q-Q Plot")
```

They are not normally distributed, so I used both boxcox and logtrans transformations to see how we can modify Lines variable.

```{r}
tmp1 <- boxcox(Lines ~ Week + I(Week^2), data=homeworks, lambda=seq(-1, 1, 0.01))
(lambda <- tmp1$x[which.max(tmp1$y)])
tmp2 <- logtrans(Lines ~ Week + I(Week^2), data=homeworks, alpha=seq(-20, 0, 0.1))
(alpha <- tmp2$x[which.max(tmp2$y)])
```

Let's see what is the better fit using AIC and BIC.

```{r}
model.bc <- lmer((Lines^lambda - 1)/lambda ~ Week + I(Week^2) + (1|Student), data=homeworks, REML=F)
model.log <- lmer(log(Lines+alpha) ~ Week + I(Week^2) + (1|Student), data=homeworks, REML=F)

aic <- c(AIC(model.bc), AIC(model.log))
bic <- c(BIC(model.bc), BIC(model.log))
crit <- as.data.frame(rbind(aic, bic))
colnames(crit) <- c("boxcox", "logtrans")
kable(crit)
```

Transformation of Lines using Box-Cox is much better when it comes to AIC and BIC criteria.

Let's get back to the assumption issue.

```{r}
qplot(sample = residuals(model.bc, scaled=TRUE), stat="qq") + geom_abline(intercept=0, slope=1, colour="red", size=1) + ggtitle("Normal Q-Q Plot")
shapiro.test(residuals(model.bc))
```

QQ-plot for residuals looks now much better. Shapiro test confirms their normality.

####Random effect

Now, normality of random effect is examined.

```{r}
qqmath(ranef(model.bc, condVar=TRUE))
shapiro.test(as.matrix(ranef(model.bc)$Student))
```

It's not perfectly normal distribution but since we have only 16 observation I would say that it is acceptable.

##Conclusions

Above analysis shows that there is a relation between Week of semester and Lines of homework report. Students modelled as random effects seem to have an impact on Lines either. When we are interested in the effect of particular Student we may obtain its estimator from the model or try to model Student as fixed effect.